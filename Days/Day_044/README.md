# Day 44

## Finetune Gemma models 

![100 days of code Day 44](../../Images/Day44.png)

Welcome to Day 44 of the 100 Days of Code challenge!


Today we will explore LoRA for finetuning Gemma (via Keras framework). LoRA is a technique for adapting pre-trained models to specific tasks with minimal additional parameters. With LoRA, you can adapt Gemma to your specific task with minimal additional parameters, making it more efficient and effective. LoRA is particularly useful when you have a small to medium-sized dataset and want to leverage the pre-trained model's knowledge.

Learn how to use [LoRA](https://youtu.be/IZXNgu4dW70?si=mlRawnm8pOOSOBaQ).

